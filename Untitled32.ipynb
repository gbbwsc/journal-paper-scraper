{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feb5f917-f573-43ec-8da7-99190abc4040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始爬取两本期刊的论文信息...\n",
      "使用CrossRef API进行爬取...\n",
      "通过CrossRef API爬取 IEEE Transactions on Knowledge and Data Engineering...\n",
      "从CrossRef API获得 50 篇IEEE论文\n",
      "IEEE爬取完成，获得 50 篇论文\n",
      "通过CrossRef API爬取 Knowledge-Based Systems...\n",
      "从CrossRef API获得 50 篇KBS论文\n",
      "KBS爬取完成，获得 50 篇论文\n",
      "\n",
      "爬取完成！耗时: 18.86 秒\n",
      "总共爬取了 100 篇论文\n",
      "\n",
      "前5篇论文信息：\n",
      "                                                                                          title                                                                                                                                 authors                                        doi abstract                                              journal  year        source\n",
      "0           Efficient EMD-based Similarity Search via Batch Pruning and Incremental Computation                                                                               Yu Chen, Yong Zhang, Jin Wang, Jiacheng Wu, Chunxiao Xing  https://doi.org/10.1109/tkde.2021.3100566      N/A  IEEE Transactions on Knowledge and Data Engineering  2021  CrossRef API\n",
      "1              Robust Detection of Link Communities With Summary Description in Social Networks                                                                          Di Jin, Xiaobao Wang, Dongxiao He, Jianwu Dang, Weixiong Zhang  https://doi.org/10.1109/tkde.2019.2958806      N/A  IEEE Transactions on Knowledge and Data Engineering  2021  CrossRef API\n",
      "2                                Improving Data Analytics with Fast and Adaptive Regularization                                        Zhaojing Luo, Shaofeng Cai, Gang Chen, Jinyang Gao, Wang-Chien Lee, Kee Yuan Ngiam, Meihui Zhang  https://doi.org/10.1109/tkde.2019.2916683      N/A  IEEE Transactions on Knowledge and Data Engineering  2021  CrossRef API\n",
      "3  Learning Fair Graph Neural Networks with Limited and Private Sensitive Attribute Information                                                                                                                  Enyan Dai, Suhang Wang  https://doi.org/10.1109/tkde.2022.3197554      N/A  IEEE Transactions on Knowledge and Data Engineering  2022  CrossRef API\n",
      "4         AliExpress Learning-To-Rank: Maximizing Online Model Performance without Going Online  Guangda Huzhang, Zhenjia Pang, Yongqing Gao, Yawen Liu, Weijie Shen, Wen-Ji Zhou, Qing Da, Anxiang Zeng, Han Yu, Yang Yu, Zhi-Hua Zhou  https://doi.org/10.1109/tkde.2021.3098898      N/A  IEEE Transactions on Knowledge and Data Engineering  2021  CrossRef API\n",
      "\n",
      "按期刊分类统计：\n",
      "journal\n",
      "IEEE Transactions on Knowledge and Data Engineering    50\n",
      "Knowledge-Based Systems                                50\n",
      "Name: count, dtype: int64\n",
      "\n",
      "数据基本信息：\n",
      "数据形状: (100, 7)\n",
      "列名: ['title', 'authors', 'doi', 'abstract', 'journal', 'year', 'source']\n",
      "数据来源: source\n",
      "CrossRef API    100\n",
      "Name: count, dtype: int64\n",
      "\n",
      "期刊分布:\n",
      "journal\n",
      "IEEE Transactions on Knowledge and Data Engineering    50\n",
      "Knowledge-Based Systems                                50\n",
      "Name: count, dtype: int64\n",
      "\n",
      "年份分布:\n",
      "year\n",
      "2020     8\n",
      "2021    21\n",
      "2022    18\n",
      "2023    19\n",
      "2024    18\n",
      "2025    16\n",
      "Name: count, dtype: int64\n",
      "\n",
      "请在Colab环境中运行以获得文件下载功能\n",
      "数据已保存到 journal_articles.csv\n",
      "\n",
      "前3行数据预览:\n",
      "\n",
      "1. Efficient EMD-based Similarity Search via Batch Pruning and Incremental Computation\n",
      "   作者: Yu Chen, Yong Zhang, Jin Wang, Jiacheng Wu, Chunxiao Xing\n",
      "   期刊: IEEE Transactions on Knowledge and Data Engineering\n",
      "   年份: 2021\n",
      "\n",
      "2. Robust Detection of Link Communities With Summary Description in Social Networks\n",
      "   作者: Di Jin, Xiaobao Wang, Dongxiao He, Jianwu Dang, Weixiong Zhang\n",
      "   期刊: IEEE Transactions on Knowledge and Data Engineering\n",
      "   年份: 2021\n",
      "\n",
      "3. Improving Data Analytics with Fast and Adaptive Regularization\n",
      "   作者: Zhaojing Luo, Shaofeng Cai, Gang Chen, Jinyang Gao, Wang-Chien Lee, Kee Yuan Ngiam, Meihui Zhang\n",
      "   期刊: IEEE Transactions on Knowledge and Data Engineering\n",
      "   年份: 2021\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Knowledge-Based Systems and IEEE TKDE论文爬取.ipynb\n",
    "\n",
    "Automatically generated by Colab.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1your_drive_link_here\n",
    "\"\"\"\n",
    "\n",
    "!pip install requests beautifulsoup4 pandas tqdm -q\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "class JournalScraper:\n",
    "    def __init__(self):\n",
    "        self.session = requests.Session()\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "            'Accept': 'application/json, text/plain, */*',\n",
    "            'Accept-Language': 'en-US,en;q=0.9',\n",
    "            'Accept-Encoding': 'gzip, deflate',\n",
    "            'Connection': 'keep-alive',\n",
    "        }\n",
    "        self.results = []\n",
    "\n",
    "    def fetch_page(self, url):\n",
    "        try:\n",
    "            response = self.session.get(url, headers=self.headers, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {url}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def fetch_json(self, url):\n",
    "        try:\n",
    "            response = self.session.get(url, headers=self.headers, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching JSON from {url}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def scrape_ieee_via_crossref(self):\n",
    "        \"\"\"使用CrossRef API获取IEEE TKDE论文\"\"\"\n",
    "        print(\"通过CrossRef API爬取 IEEE Transactions on Knowledge and Data Engineering...\")\n",
    "        \n",
    "        current_year = datetime.now().year\n",
    "        start_year = current_year - 5\n",
    "        articles = []\n",
    "        \n",
    "        base_url = \"https://api.crossref.org/works\"\n",
    "        params = {\n",
    "            'query.container-title': 'IEEE Transactions on Knowledge and Data Engineering',\n",
    "            'filter': f'from-pub-date:{start_year}-01-01',\n",
    "            'rows': 50,\n",
    "            'select': 'DOI,title,author,abstract,published,ISSN'\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = self.session.get(base_url, params=params, headers=self.headers)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            for item in data.get('message', {}).get('items', []):\n",
    "                try:\n",
    "                    # 检查是否是IEEE TKDE期刊\n",
    "                    issn_list = item.get('ISSN', [])\n",
    "                    if not any('1041-4347' in issn for issn in issn_list if issn):\n",
    "                        continue\n",
    "                    \n",
    "                    title = item.get('title', ['N/A'])[0] if item.get('title') else 'N/A'\n",
    "                    \n",
    "                    authors = []\n",
    "                    for author in item.get('author', []):\n",
    "                        given = author.get('given', '')\n",
    "                        family = author.get('family', '')\n",
    "                        authors.append(f\"{given} {family}\".strip())\n",
    "                    authors_str = ', '.join(authors) if authors else 'N/A'\n",
    "                    \n",
    "                    doi = item.get('DOI', 'N/A')\n",
    "                    abstract = item.get('abstract', 'N/A')\n",
    "                    \n",
    "                    # 获取年份\n",
    "                    year = current_year\n",
    "                    if item.get('published', {}).get('date-parts'):\n",
    "                        year = item['published']['date-parts'][0][0]\n",
    "                    \n",
    "                    articles.append({\n",
    "                        'title': title,\n",
    "                        'authors': authors_str,\n",
    "                        'doi': f\"https://doi.org/{doi}\" if doi != 'N/A' else 'N/A',\n",
    "                        'abstract': abstract,\n",
    "                        'journal': 'IEEE Transactions on Knowledge and Data Engineering',\n",
    "                        'year': year,\n",
    "                        'source': 'CrossRef API'\n",
    "                    })\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error parsing IEEE item: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            print(f\"从CrossRef API获得 {len(articles)} 篇IEEE论文\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error with CrossRef API: {e}\")\n",
    "            # 备用方案\n",
    "            articles = self.get_sample_ieee_data()\n",
    "        \n",
    "        return articles\n",
    "\n",
    "    def scrape_kbs_via_crossref(self):\n",
    "        \"\"\"使用CrossRef API获取Knowledge-Based Systems论文\"\"\"\n",
    "        print(\"通过CrossRef API爬取 Knowledge-Based Systems...\")\n",
    "        \n",
    "        current_year = datetime.now().year\n",
    "        start_year = current_year - 5\n",
    "        articles = []\n",
    "        \n",
    "        base_url = \"https://api.crossref.org/works\"\n",
    "        params = {\n",
    "            'query.container-title': 'Knowledge-Based Systems',\n",
    "            'filter': f'from-pub-date:{start_year}-01-01',\n",
    "            'rows': 50,\n",
    "            'select': 'DOI,title,author,abstract,published,ISSN'\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = self.session.get(base_url, params=params, headers=self.headers)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            for item in data.get('message', {}).get('items', []):\n",
    "                try:\n",
    "                    # 检查是否是Knowledge-Based Systems期刊\n",
    "                    issn_list = item.get('ISSN', [])\n",
    "                    if not any('0950-7051' in issn for issn in issn_list if issn):\n",
    "                        continue\n",
    "                    \n",
    "                    title = item.get('title', ['N/A'])[0] if item.get('title') else 'N/A'\n",
    "                    \n",
    "                    authors = []\n",
    "                    for author in item.get('author', []):\n",
    "                        given = author.get('given', '')\n",
    "                        family = author.get('family', '')\n",
    "                        authors.append(f\"{given} {family}\".strip())\n",
    "                    authors_str = ', '.join(authors) if authors else 'N/A'\n",
    "                    \n",
    "                    doi = item.get('DOI', 'N/A')\n",
    "                    abstract = item.get('abstract', 'N/A')\n",
    "                    \n",
    "                    # 获取年份\n",
    "                    year = current_year\n",
    "                    if item.get('published', {}).get('date-parts'):\n",
    "                        year = item['published']['date-parts'][0][0]\n",
    "                    \n",
    "                    articles.append({\n",
    "                        'title': title,\n",
    "                        'authors': authors_str,\n",
    "                        'doi': f\"https://doi.org/{doi}\" if doi != 'N/A' else 'N/A',\n",
    "                        'abstract': abstract,\n",
    "                        'journal': 'Knowledge-Based Systems',\n",
    "                        'year': year,\n",
    "                        'source': 'CrossRef API'\n",
    "                    })\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error parsing KBS item: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            print(f\"从CrossRef API获得 {len(articles)} 篇KBS论文\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error with CrossRef API for KBS: {e}\")\n",
    "            # 备用方案\n",
    "            articles = self.get_sample_kbs_data()\n",
    "        \n",
    "        return articles\n",
    "\n",
    "    def get_sample_ieee_data(self):\n",
    "        \"\"\"IEEE示例数据\"\"\"\n",
    "        return [\n",
    "            {\n",
    "                'title': 'Machine Learning for Knowledge Discovery in Databases',\n",
    "                'authors': 'John Smith, Jane Doe, Robert Johnson',\n",
    "                'doi': 'https://doi.org/10.1109/TKDE.2023.1234567',\n",
    "                'abstract': 'This paper presents a novel machine learning approach for knowledge discovery in large databases. The method combines deep learning with traditional data mining techniques.',\n",
    "                'journal': 'IEEE Transactions on Knowledge and Data Engineering',\n",
    "                'year': 2023,\n",
    "                'source': 'Sample Data'\n",
    "            },\n",
    "            {\n",
    "                'title': 'Deep Learning Approaches for Data Mining',\n",
    "                'authors': 'Alice Brown, Bob Wilson',\n",
    "                'doi': 'https://doi.org/10.1109/TKDE.2022.9876543',\n",
    "                'abstract': 'A comprehensive survey of deep learning techniques applied to data mining problems, including classification, clustering, and association rule mining.',\n",
    "                'journal': 'IEEE Transactions on Knowledge and Data Engineering',\n",
    "                'year': 2022,\n",
    "                'source': 'Sample Data'\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    def get_sample_kbs_data(self):\n",
    "        \"\"\"KBS示例数据\"\"\"\n",
    "        return [\n",
    "            {\n",
    "                'title': 'Knowledge-Based Systems for Decision Support',\n",
    "                'authors': 'Michael Chen, Sarah Lee',\n",
    "                'doi': 'https://doi.org/10.1016/j.knosys.2023.123456',\n",
    "                'abstract': 'This research explores the development of knowledge-based systems for enhanced decision support in complex environments.',\n",
    "                'journal': 'Knowledge-Based Systems',\n",
    "                'year': 2023,\n",
    "                'source': 'Sample Data'\n",
    "            },\n",
    "            {\n",
    "                'title': 'Artificial Intelligence in Knowledge Management',\n",
    "                'authors': 'David Kim, Emily Wang',\n",
    "                'doi': 'https://doi.org/10.1016/j.knosys.2022.654321',\n",
    "                'abstract': 'An investigation into the role of artificial intelligence in modern knowledge management systems, focusing on natural language processing and machine learning techniques.',\n",
    "                'journal': 'Knowledge-Based Systems',\n",
    "                'year': 2022,\n",
    "                'source': 'Sample Data'\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    def run(self):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        print(\"开始爬取两本期刊的论文信息...\")\n",
    "        print(\"使用CrossRef API进行爬取...\")\n",
    "        \n",
    "        # 爬取IEEE\n",
    "        ieee_articles = self.scrape_ieee_via_crossref()\n",
    "        print(f\"IEEE爬取完成，获得 {len(ieee_articles)} 篇论文\")\n",
    "        \n",
    "        # 爬取KBS\n",
    "        kbs_articles = self.scrape_kbs_via_crossref()\n",
    "        print(f\"KBS爬取完成，获得 {len(kbs_articles)} 篇论文\")\n",
    "        \n",
    "        self.results = ieee_articles + kbs_articles\n",
    "        \n",
    "        # 保存结果\n",
    "        if self.results:\n",
    "            df = pd.DataFrame(self.results)\n",
    "            filename = 'journal_articles.csv'\n",
    "            df.to_csv(filename, index=False, encoding='utf-8', escapechar='\\\\')\n",
    "            \n",
    "            end_time = time.time()\n",
    "            print(f\"\\n爬取完成！耗时: {end_time - start_time:.2f} 秒\")\n",
    "            print(f\"总共爬取了 {len(self.results)} 篇论文\")\n",
    "            \n",
    "            print(\"\\n前5篇论文信息：\")\n",
    "            print(df.head().to_string())\n",
    "            \n",
    "            print(\"\\n按期刊分类统计：\")\n",
    "            print(df['journal'].value_counts())\n",
    "            \n",
    "            return df, filename\n",
    "        else:\n",
    "            print(\"没有爬取到任何论文数据，使用示例数据演示\")\n",
    "            # 使用示例数据\n",
    "            sample_data = self.get_sample_ieee_data() + self.get_sample_kbs_data()\n",
    "            df = pd.DataFrame(sample_data)\n",
    "            filename = 'journal_articles_sample.csv'\n",
    "            df.to_csv(filename, index=False, encoding='utf-8')\n",
    "            print(\"已生成示例数据文件\")\n",
    "            return df, filename\n",
    "\n",
    "# 运行爬虫\n",
    "scraper = JournalScraper()\n",
    "df, filename = scraper.run()\n",
    "\n",
    "# 显示数据基本信息\n",
    "print(\"\\n数据基本信息：\")\n",
    "print(f\"数据形状: {df.shape}\")\n",
    "print(f\"列名: {list(df.columns)}\")\n",
    "print(f\"数据来源: {df['source'].value_counts()}\")\n",
    "\n",
    "# 显示一些统计信息\n",
    "print(\"\\n期刊分布:\")\n",
    "print(df['journal'].value_counts())\n",
    "\n",
    "print(\"\\n年份分布:\")\n",
    "print(df['year'].value_counts().sort_index())\n",
    "\n",
    "# 提供下载链接\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download(filename)\n",
    "    print(f\"\\n{filename} 文件已准备好下载\")\n",
    "except:\n",
    "    print(f\"\\n请在Colab环境中运行以获得文件下载功能\")\n",
    "    print(f\"数据已保存到 {filename}\")\n",
    "\n",
    "# 显示前几行数据\n",
    "print(\"\\n前3行数据预览:\")\n",
    "for i, row in df.head(3).iterrows():\n",
    "    print(f\"\\n{i+1}. {row['title']}\")\n",
    "    print(f\"   作者: {row['authors']}\")\n",
    "    print(f\"   期刊: {row['journal']}\")\n",
    "    print(f\"   年份: {row['year']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720f746e-f816-4e0c-b525-6ea547489e62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
